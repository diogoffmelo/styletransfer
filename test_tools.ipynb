{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc as misc\n",
    "from skimage.transform import resize as imresize\n",
    "import numpy as np\n",
    "from scipy.io import loadmat as load_from_matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(path):\n",
    "    return imresize(plt.imread(path).astype(np.float32)/255, (244, 244), mode='reflect')\n",
    "\n",
    "def imbatch1(img):\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "\n",
    "matvgg19 = load_from_matlab('/home/diogo/data/deep_studies/style_transfer/imagenet-vgg-verydeep-19.mat')\n",
    "matclasses = matvgg19['classes'][0, 0] \n",
    "matlayers = matvgg19['layers'][0]\n",
    "\n",
    "def read_classes(matclasses):\n",
    "    idxs, names = matclasses\n",
    "    idxs = idxs[0]\n",
    "    names = names[0]\n",
    "    fname = [n[0].split(',')[0] for n in names]\n",
    "    \n",
    "    return fname, names, idxs, \n",
    "\n",
    "name, _, _, = read_classes(matclasses)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['conv1_1'], dtype='<U7')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = matlayers[0]\n",
    "layer[0, 0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "STRIDE1 = (1, 1, 1, 1)\n",
    "PIXEL_SCALE = float(255)\n",
    "PIXEL_OFFSET = np.array([103.939, 116.779, 123.68])\n",
    "\n",
    "\n",
    "def conv(inputs, matlayer):\n",
    "    \"\"\"\n",
    "    Build an convolutional layer from matlab weitghs on data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Raise an error before is too late ;)\n",
    "    W, B = matlayer['weights'][0]\n",
    "    It, Ih, Iw, Ic = inputs.shape\n",
    "    Ww, Wh, Wi, Wo = W.shape\n",
    "    assert Wi == Ic\n",
    "    assert B.shape == (1, Wo)\n",
    "\n",
    "    # Matlab to tensorflow\n",
    "    W = W.transpose((1, 0, 2, 3))\n",
    "    B = B.reshape(-1)\n",
    "\n",
    "    tfW = tf.constant(W)\n",
    "    tfB = tf.constant(B)\n",
    "    return tf.nn.conv2d(inputs, tfW, STRIDE1, 'SAME') + tfB\n",
    "\n",
    "\n",
    "def relu(inputs, matlayer):\n",
    "    # Raise an error before is too late.\n",
    "    assert matlayer['type'][0] == 'relu'\n",
    "\n",
    "    return tf.nn.relu(inputs)\n",
    "\n",
    "\n",
    "def maxpool(inputs, matlayer):\n",
    "    # Yep, another error check.\n",
    "    assert matlayer['type'][0] == 'pool'\n",
    "\n",
    "    return tf.layers.max_pooling2d(inputs, 2, 2, padding='VALID')\n",
    "\n",
    "\n",
    "def flatten(inputs, matlayer):\n",
    "    # Better sooner than late.\n",
    "    W, B = matlayer['weights'][0]\n",
    "    It, Ih, Iw, Ic = inputs.shape\n",
    "    Ww, Wh, Wi, Wo = W.shape\n",
    "    assert (Wh, Ww, Wi) == (Ih, Iw, Ic)\n",
    "    assert B.shape == (1, Wo)\n",
    "    \n",
    "    return tf.layers.flatten(inputs)\n",
    "\n",
    "\n",
    "def dense(inputs, matlayer):\n",
    "    # Yo know what they say about precautoins.\n",
    "    W, B = matlayer['weights'][0]\n",
    "    Wh, Ww, Wi, Wo = W.shape\n",
    "    It, Il = inputs.shape\n",
    "    Wri, Wro = W.reshape([-1, Wo]).shape\n",
    "    assert (Wh * Ww * Wi) == Wri\n",
    "    assert Wro == Wo    \n",
    "    assert B.shape == (1, Wo)\n",
    "    assert Wri == Il\n",
    "    \n",
    "    tfW = tf.constant(W.reshape([-1, Wo]))\n",
    "    tfB = tf.constant(B)\n",
    "    return tf.matmul(inputs, tfW) + tfB\n",
    "\n",
    "\n",
    "def softmax(inputs, matlayer):\n",
    "    # I know, i'm getting old, so what?\n",
    "    assert matlayer['type'][0] == 'softmax'\n",
    "    \n",
    "    return tf.nn.softmax(inputs)\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "layers = OrderedDict()\n",
    "tf_input_image = tf.placeholder(shape=[1, 244, 244, 3], dtype=tf.float32)\n",
    "x = PIXEL_SCALE * tf_input_image - PIXEL_OFFSET\n",
    "\n",
    "layers['input'] = tf_input_image\n",
    "layers['processed_input'] = x\n",
    "\n",
    "\n",
    "mat_layers_map = {\n",
    "    'conv': conv,\n",
    "    'relu': relu,\n",
    "    'pool': maxpool,\n",
    "    'dense': dense,\n",
    "    'softmax': softmax,\n",
    "}\n",
    "\n",
    "usetop = True\n",
    "verbose = False\n",
    "\n",
    "def layerTypeName(matlayer):\n",
    "    ltype, lname = matlayer['type'][0], matlayer['name'][0]\n",
    "    \n",
    "    # Optimizes fully connected layers as tensorflow dense layer\n",
    "    if ltype == 'conv' and lname.startswith('fc'):\n",
    "        ltype = 'dense'\n",
    "    \n",
    "    return ltype, lname\n",
    "\n",
    "for matlayer in matlayers:\n",
    "    matlayer = matlayer[0, 0]\n",
    "    ltype, lname = layerTypeName(matlayer)    \n",
    "    if lname == 'fc6':\n",
    "        if usetop:\n",
    "            if verbose:\n",
    "                print('Creating layer{} of type {}'.format('flatten', 'reshape'))\n",
    "\n",
    "            x = flatten(x, matlayer)\n",
    "            layers['flatten'] = x\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print('Reading layer{} of type{}'.format(lname, ltype))\n",
    "            \n",
    "    x = mat_layers_map[ltype](x, matlayer)\n",
    "    layers[lname] = x\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tusker', 0.14157006), ('Indian elephant', 0.11259125), ('African elephant', 0.096443094), ('triceratops', 0.08624849), ('water buffalo', 0.07027102)]\n"
     ]
    }
   ],
   "source": [
    "img = imread('/home/diogo/data/deep_studies/style_transfer/tusker.jpeg')\n",
    "imgbt = imbatch1(img)\n",
    "with sess.as_default():\n",
    "    npclasses = sess.run(x, feed_dict={tf_input_image:imgbt})\n",
    "    idxs = np.argsort(npclasses)\n",
    "    print(list(reversed(list(zip(np.asarray(name)[idxs[0, -5:]], npclasses[0, idxs[0, -5:]])))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n",
      "[0.14157006 0.11259125 0.09644309 0.08624849 0.07027102]\n"
     ]
    }
   ],
   "source": [
    "XX = npclasses#p.concatenate([npclasses, npclasses[:, ::-1]])\n",
    "print(XX.shape)\n",
    "\n",
    "idxs = np.argsort(XX)[:, -5:]\n",
    "#XX[idxs]\n",
    "\n",
    "#np.partition(XX, 2)\n",
    "\n",
    "#print(XX)\n",
    "print(XX[0, idxs[0, ::-1]])\n",
    "#print(XX[1, idxs[1, ::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_layers_map['relu']\n",
    "\n",
    "#matlayers = matvgg19['layers'][0]\n",
    "#matlayers[0]['weights'][0, 0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.autoencodernet import StyleAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "tfx = tf.layers.Input(shape=(256, 256, 3))\n",
    "tfxrec = StyleAutoEncoder(tfx)\n",
    "\n",
    "\n",
    "loss = tf.nn.l2_loss(tfx - tfxrec.output)#/(256*256*3)\n",
    "train = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    nptfx = sess.run(tfxrec.output, feed_dict={tfx: 255 * np.random.random([1, 256, 256, 3])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nptfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(nptfx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nptfx.min(), nptfx.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('/home/diogo/data/deep_studies/style_transfer/night.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.min(), img.max())\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = os.listdir('/home/diogo/data/deep_studies/style_transfer/fast-style-transfer/data/train2014')\n",
    "\n",
    "def plot_img_cmp(X, Xt, nimages=10):\n",
    "    imgidxs = np.random.choice(X.shape[0], nimages)\n",
    "\n",
    "    fig, axeslist = plt.subplots(ncols=nimages, nrows=2, sharex=True, sharey=True)\n",
    "    fig.set_size_inches(16, 8)\n",
    "    #fig.subplots_adjust(left=0, bottom=0, right=1, top=0.1, wspace=0, hspace=0)\n",
    "    \n",
    "    for i in range(nimages):\n",
    "        axeslist[0, i].imshow(X[imgidxs[i]])\n",
    "        axeslist[0, i].set_axis_off()\n",
    "        \n",
    "        axeslist[1, i].imshow(Xt[imgidxs[i]])\n",
    "        axeslist[1, i].set_axis_off()\n",
    "\n",
    "    fig.subplots_adjust(wspace=0, hspace=-0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "base = '/home/diogo/data/deep_studies/style_transfer/fast-style-transfer/data/train2014/'\n",
    "\n",
    "food = {tfx: 255*imbatch1(img)}\n",
    "with sess.as_default():\n",
    "    for i in range(50):\n",
    "        npimages = np.asarray([255 * imread(base + x) for x in np.random.choice(files, 5)], dtype=np.float32)\n",
    "        food = {tfx: npimages}\n",
    "        l, _ = sess.run([loss, train], feed_dict=food)\n",
    "        ll.append(l)\n",
    "        if i % 5 == 0 and i > 0:\n",
    "            imgt = sess.run(tfxrec.output, feed_dict=food)\n",
    "            imgt = imgt\n",
    "            #imgt = np.squeeze(imgt, 0)\n",
    "            #clear_output()\n",
    "            #plt.ioff()\n",
    "            #_ll = ll[:min(len(ll), 200)]\n",
    "            #plt.plot(np.arange(len(_ll)), _ll)\n",
    "            plt.plot(np.arange(len(ll)), ll)\n",
    "            plt.show()\n",
    "            \n",
    "            #plot_img_random(Xt)\n",
    "            plot_img_cmp(npimages/255, imgt/255, 3)\n",
    "            #plt.imshow(imgt/255)\n",
    "            plt.show()\n",
    "            clear_output(wait=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgt.min(), imgt.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  np.asarray([255 * imread('/home/diogo/data/deep_studies/style_transfer/fast-style-transfer/data/train2014/' + x) for x in np.random.choice(files, 10)], dtype=np.float32)\n",
    "\n",
    "fig, axeslist = plt.subplots(ncols=5, nrows=1, sharey=True)\n",
    "for i in range(5):\n",
    "    fig.set_size_inches(14, 3)\n",
    "    axeslist.ravel()[i].imshow(X[i]/255)\n",
    "    axeslist.ravel()[i].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[1]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def need_input(layer):\n",
    "    def new_function(s, *args, **kwargs):\n",
    "        original_function(*args, **kwargs)\n",
    "        print(\"Hello, galaxy!\")\n",
    "    return new_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = data['layers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[37][0][0][0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "STRIDE1 = (1, 1, 1, 1)\n",
    "PIXEL_SCALE = float(255)\n",
    "PIXEL_OFFSET = np.array([103.939, 116.779, 123.68])\n",
    "\n",
    "\n",
    "def conv(data, filters, size, inputs):\n",
    "    \"\"\"\n",
    "    Build an convolutional layer from matlab weitghs on data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Raise an error before is too late ;)\n",
    "    W, B = data[0][0][0][0]\n",
    "    It, Ih, Iw, Ic = inputs.shape\n",
    "    assert W.shape == (size, size, Ic, filters)\n",
    "    assert B.shape == (1, filters)\n",
    "\n",
    "    # Matlab to tensorflow\n",
    "    W = W.transpose((1, 0, 2, 3))\n",
    "    B = B.reshape(-1)\n",
    "\n",
    "    tfW = tf.constant(W)\n",
    "    tfB = tf.constant(B)\n",
    "    return tf.nn.conv2d(inputs, tfW, STRIDE1, 'SAME') + tfB\n",
    "\n",
    "\n",
    "def relu(data, inputs):\n",
    "    # Raise an error before is too late.\n",
    "    assert data[0][0][0][0] == 'relu'\n",
    "\n",
    "    return tf.nn.relu(inputs)\n",
    "\n",
    "\n",
    "def maxpool(data, inputs):\n",
    "    # Yep, another error check.\n",
    "    assert 'pool' in data[0][0][0][0]\n",
    "\n",
    "    return tf.layers.max_pooling2d(inputs, 2, 2, padding='VALID')\n",
    "\n",
    "\n",
    "def flatten(data, inputs):\n",
    "    # Better sooner than late.\n",
    "    W, B = data[0][0][0][0]\n",
    "    It, Ih, Iw, Ic = inputs.shape\n",
    "    Ww, Wh, Wi, Wo = W.shape\n",
    "    assert (Wh, Ww, Wi) == (Ih, Iw, Ic)\n",
    "    assert B.shape == (1, Wo)\n",
    "    \n",
    "    return tf.layers.flatten(inputs)\n",
    "\n",
    "\n",
    "def dense(data, inputs):\n",
    "    # Yo know what they say about precautoins.\n",
    "    W, B = data[0][0][0][0]\n",
    "    Wh, Ww, Wi, Wo = W.shape\n",
    "    It, Il = inputs.shape\n",
    "    Wri, Wro = W.reshape([-1, Wo]).shape\n",
    "    assert (Wh * Ww * Wi) == Wri\n",
    "    assert Wro == Wo    \n",
    "    assert B.shape == (1, Wo)\n",
    "    assert Wri == Il\n",
    "    \n",
    "    tfW = tf.constant(W.reshape([-1, Wo]))\n",
    "    tfB = tf.constant(B)\n",
    "    return tf.matmul(inputs, tfW) + tfB\n",
    "\n",
    "\n",
    "def softmax(data, inputs):\n",
    "    # I know, i'm getting old, so what?\n",
    "    assert 'softmax' == data[0][0][0][0]\n",
    "    \n",
    "    return tf.nn.softmax(inputs)\n",
    "\n",
    "\n",
    "\n",
    "tf_input_image = tf.placeholder(shape=[1, 244, 244, 3], dtype=tf.float32)\n",
    "x = PIXEL_SCALE * tf_input_image - PIXEL_OFFSET\n",
    "\n",
    "\n",
    "#for layerspec in weights:\n",
    "#    layerspec = layerspec[0, 0]\n",
    "#    ltype = layerspec['type'][0]\n",
    "#    lname = layerspec['name'][0]\n",
    "#    \n",
    "#    if ltype == 'conv':\n",
    "#        print(ltype, lname, layerspec['weights'][0, 0].shape, layerspec['weights'][0, 1].shape, layerspec['pad'], layerspec['stride'])\n",
    "#    elif ltype == 'pool':\n",
    "#        print(ltype, lname, layerspec['method'], layerspec['pad'], layerspec['stride'])\n",
    "#    elif ltype == 'relu':\n",
    "#        print(ltype, lname)\n",
    "#    else:\n",
    "#        print(layerspec.dtype, layerspec['type'], layerspec['name']\n",
    "#\n",
    "#    if lname == 'pool5':\n",
    "#        break\n",
    "\n",
    "\n",
    "#x = 255 * tf.reverse(tf_input_image, axis=[-1]) - offset\n",
    "\n",
    "#x = tf_input_image\n",
    "\n",
    "x = conv(weights[0], 64, 3, x)\n",
    "x = relu(weights[1], x)\n",
    "x = conv(weights[2], 64, 3, x)\n",
    "x = relu(weights[3], x)\n",
    "x = maxpool(weights[4], x)\n",
    "\n",
    "x = conv(weights[5], 128, 3, x)\n",
    "x = relu(weights[6], x)\n",
    "x = conv(weights[7], 128, 3, x)\n",
    "x = relu(weights[8], x)\n",
    "x = maxpool(weights[9], x)\n",
    "\n",
    "x = conv(weights[10], 256, 3, x)\n",
    "x = relu(weights[11], x)\n",
    "x = conv(weights[12], 256, 3, x)\n",
    "x = relu(weights[13], x)\n",
    "x = conv(weights[14], 256, 3, x)\n",
    "x = relu(weights[15], x)\n",
    "x = conv(weights[16], 256, 3, x)\n",
    "x = relu(weights[17], x)\n",
    "x = maxpool(weights[18], x)\n",
    "\n",
    "x = conv(weights[19], 512, 3, x)\n",
    "x = relu(weights[20], x)\n",
    "x = conv(weights[21], 512, 3, x)\n",
    "x = relu(weights[22], x)\n",
    "x = conv(weights[23], 512, 3, x)\n",
    "x = relu(weights[24], x)\n",
    "x = conv(weights[25], 512, 3, x)\n",
    "x = relu(weights[26], x)\n",
    "x = maxpool(weights[27], x)\n",
    "\n",
    "x = conv(weights[28], 512, 3, x)\n",
    "x = relu(weights[29], x)\n",
    "x = conv(weights[30], 512, 3, x)\n",
    "x = relu(weights[31], x)\n",
    "x = conv(weights[32], 512, 3, x)\n",
    "x = relu(weights[33], x)\n",
    "x = conv(weights[34], 512, 3, x)\n",
    "x = relu(weights[35], x)\n",
    "x = maxpool(weights[36], x)\n",
    "\n",
    "x = flatten(weights[37], x)\n",
    "x = dense(weights[37], x)\n",
    "x = relu(weights[38], x)\n",
    "x = dense(weights[39], x)\n",
    "x = relu(weights[40], x)\n",
    "x = dense(weights[41], x)\n",
    "tf_output_classes = softmax(weights[42], x)\n",
    "\n",
    "assert x.shape == (1, 1000)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('/home/diogo/data/deep_studies/style_transfer/tusker.jpeg')\n",
    "#plt.imshow(img)\n",
    "imgbt = imbatch1(img)\n",
    "#print(imgbt.min(), imgbt.max(), imgbt.shape)\n",
    "\n",
    "#imgbt = imgbt[:, :, :, (2, 1, 0)] - np.asarray([123.68 , 116.779, 103.939])# np.asarray([103.939, 116.779, 123.68])/255\n",
    "\n",
    "tt = (0, 1, 2)\n",
    "\n",
    "#imgbt = 255*imgbt[:, :, :, tt] - np.asarray([103.939, 116.779, 123.68])\n",
    "\n",
    "#print(imgbt.min(), imgbt.max(), imgbt.shape)\n",
    "\n",
    "\n",
    "#imgbt = imgbt[(0, 3, 2, 1) ] - np.asarray([103.939, 116.779, 123.68])/255\n",
    "\n",
    "#print(type(imgbt), type(tf_output_classes), type(tf_input_image))\n",
    "\n",
    "with sess.as_default():\n",
    "    npclasses = sess.run(tf_output_classes, feed_dict={tf_input_image:imgbt})\n",
    "    idxs = np.argsort(npclasses)\n",
    "    print(list(reversed(list(zip(np.asarray(name)[idxs[0, -5:]], npclasses[0, idxs[0, -5:]])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.zeros((7, 7, 512, 4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, B = weights[37][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['normalization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_classes(data):\n",
    "    idxs, names = data['classes'][0, 0]\n",
    "    idxs = idxs[0]\n",
    "    names = names[0]\n",
    "    fname = [n[0].split(',')[0] for n in names]\n",
    "    \n",
    "    return fname, names, idxs, \n",
    "\n",
    "name, _, _, = read_classes(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RGB -> BGR\n",
    "#(0, 1, 2) -> (2, 1, 0) \n",
    "\n",
    "np.asarray([103.939, 116.779, 123.68])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[37][0, 0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layerspec in weights:\n",
    "    layerspec = layerspec[0, 0]\n",
    "    ltype = layerspec['type'][0]\n",
    "    lname = layerspec['name'][0]\n",
    "    if ltype == 'conv':\n",
    "        print(ltype, lname, layerspec['weights'][0, 0].shape, layerspec['weights'][0, 1].shape, layerspec['pad'], layerspec['stride'])\n",
    "    elif ltype == 'pool':\n",
    "        print(ltype, lname, layerspec['method'], layerspec['pad'], layerspec['stride'])\n",
    "    elif ltype == 'relu':\n",
    "        print(ltype, lname)\n",
    "    else:\n",
    "        print(layerspec.dtype, layerspec['type'], layerspec['name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0][0, 0]['pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0][0, 0]['stride']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "PIXEL_SCALE = float(255)\n",
    "PIXEL_OFFSET = np.array([103.939, 116.779, 123.68])\n",
    "\n",
    "def conv(inputs, matlayer):\n",
    "    \"\"\"\n",
    "    Build an convolutional layer from matlab weitghs on data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Raise an error before is too late ;)\n",
    "    W, B = matlayer['weights'][0]\n",
    "    stride = np.ones([1,4], dtype=np.int)\n",
    "    stride[[1,2]] = matlayer['stride'][0]\n",
    "    pad = matlayer['pad'][0]\n",
    "\n",
    "    Ww, Wh, Wi, Wo = W.shape\n",
    "    It, Ih, Iw, Ic = inputs.shape\n",
    "    assert Wi == Ic\n",
    "    assert B.shape == (1, Wo)\n",
    "\n",
    "    # Matlab to tensorflow\n",
    "    W = W.transpose((1, 0, 2, 3))\n",
    "    B = B.reshape(-1)\n",
    "\n",
    "    tfW = tf.constant(W)\n",
    "    tfB = tf.constant(B)\n",
    "    return tf.nn.conv2d(inputs, tfW, stride, 'SAME') + tfB\n",
    "\n",
    "\n",
    "\n",
    "def conv(data, filters, size, inputs):\n",
    "    W, B = data[0][0][0][0]\n",
    "    T, H, Ci, C = inputs.shape\n",
    "    \n",
    "    assert W.shape == (size, size, C, filters)\n",
    "    assert B.shape == (1, filters)\n",
    "    assert C == W.shape[2]\n",
    "    \n",
    "    print('OK!')\n",
    "    \n",
    "    W = W.transpose((1, 0, 2, 3))\n",
    "    B = B.reshape(-1)\n",
    "\n",
    "\n",
    "    tfW = tf.constant(W)\n",
    "    tfB = tf.constant(B)\n",
    "\n",
    "    _conv = tf.nn.conv2d(inputs, tfW, STRIDE1, 'SAME') + tfB\n",
    "    print(inputs.shape, '->', _conv.shape)\n",
    "    return _conv\n",
    "\n",
    "def relu(data, inputs):\n",
    "    assert data[0][0][0][0] == 'relu'\n",
    "    print('OK!')\n",
    "    return tf.nn.relu(inputs)\n",
    "\n",
    "def maxpool(data, inputs):\n",
    "    assert 'pool' in data[0][0][0][0]\n",
    "    \n",
    "    _l = tf.layers.max_pooling2d(inputs, 2, 2, padding='VALID')\n",
    "    \n",
    "    print(inputs.shape, '->', _l.shape)\n",
    "    return _l\n",
    "\n",
    "\n",
    "def flatten(data, inputs):\n",
    "    W, B = data[0][0][0][0]\n",
    "    Tx, Hx, Wx, Cx = inputs.shape\n",
    "    WH, WW, Wi, Wo = W.shape\n",
    "\n",
    "    print(inputs.shape, W.shape, B.shape)\n",
    "    \n",
    "    assert (WH, WH, Wi) == (Hx, Wx, Cx)\n",
    "    print('OK!')\n",
    "    return tf.layers.flatten(inputs)\n",
    "\n",
    "\n",
    "def dense(data, x):\n",
    "    W, B = data[0][0][0][0]\n",
    "    WH, WH, Wi, Wo = W.shape\n",
    "    W = W.reshape([-1, Wo])\n",
    "    \n",
    "    I, O = W.shape\n",
    "\n",
    "    assert B.shape == (1, Wo)\n",
    "    \n",
    "    T, L = x.shape\n",
    "    \n",
    "    assert L == I\n",
    "    print('OK!')\n",
    "    return tf.matmul(x, W) + B\n",
    "    \n",
    "def softmax(data, x):\n",
    "    assert 'softmax' == data[0][0][0][0]\n",
    "    print('OK!')\n",
    "    return tf.nn.softmax(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19specs['classes'][0, 0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "tensorflowgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
